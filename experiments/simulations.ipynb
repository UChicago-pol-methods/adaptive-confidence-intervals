{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script runs simulations reported in our paper Confidence Intervals for Policy Evaluation in Adaptive Experiments (https://arxiv.org/abs/1911.02768)\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from time import time\n",
    "from sys import argv\n",
    "from random import choice\n",
    "from time import time\n",
    "from os.path import dirname, realpath, join, exists\n",
    "from os import makedirs, chmod\n",
    "from getpass import getuser\n",
    "\n",
    "from adaptive_CI.experiments import run_mab_experiment\n",
    "from adaptive_CI.compute import stick_breaking\n",
    "from adaptive_CI.inference import *\n",
    "from adaptive_CI.weights import *\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_time = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sims = 200 if on_sherlock() else 1\n",
    "\n",
    "# DGP specification\n",
    "# ----------------------------------------------------\n",
    "noise_func = 'uniform'\n",
    "truths = {\n",
    "    'nosignal': np.array([1., 1., 1.]),\n",
    "    'lowSNR': np.array([.9, 1., 1.1]),\n",
    "    'highSNR': np.array([.5, 1., 1.5])\n",
    "}\n",
    "if on_sherlock():\n",
    "    Ts = [1_000, 5_000, 10_000, 50_000, 100_000]\n",
    "else:\n",
    "    Ts = [100_000]\n",
    "floor_decays = [.7]\n",
    "initial = 5  # initial number of samples of each arm to do pure exploration\n",
    "exploration = 'TS'\n",
    "noise_scale = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = []\n",
    "df_lambdas = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time passed 18.85572910308838s\n"
     ]
    }
   ],
   "source": [
    "# Run simulations\n",
    "for s in range(num_sims):\n",
    "    if (s+1) % 10 == 0:\n",
    "        print(f'Running simulation {s+1}/{num_sims}')\n",
    "\n",
    "    \"\"\" Experiment configuration \"\"\"\n",
    "    T = choice(Ts)  # number of samples\n",
    "    experiment = choice(list(truths.keys()))\n",
    "    truth = truths[experiment]\n",
    "    K = len(truth)  # number of arms\n",
    "    floor_start = 1/K\n",
    "    floor_decay = choice(floor_decays)\n",
    "\n",
    "    \"\"\" Generate data \"\"\"\n",
    "    noise = np.random.uniform(-noise_scale, noise_scale, size=(T, K))\n",
    "    ys = truth + noise\n",
    "\n",
    "    \"\"\" Run experiment \"\"\"\n",
    "    data = run_mab_experiment(\n",
    "        ys,\n",
    "        initial=initial,\n",
    "        floor_start=floor_start,\n",
    "        floor_decay=floor_decay,\n",
    "        exploration=exploration)\n",
    "\n",
    "    probs = data['probs']\n",
    "    rewards = data['rewards']\n",
    "    arms = data['arms']\n",
    "\n",
    "    \"\"\" Compute AIPW scores \"\"\"\n",
    "    muhat = np.row_stack([np.zeros(K), sample_mean(rewards, arms, K)[:-1]])\n",
    "    scores = aw_scores(rewards, arms, probs, muhat)\n",
    "\n",
    "    \"\"\" Compute weights \"\"\"\n",
    "    # Two-point allocation rate\n",
    "    twopoint_ratio = twopoint_stable_var_ratio(e=probs, alpha=floor_decay)\n",
    "    twopoint_ratio_old = twopoint_stable_var_ratio_old(probs, floor_start, floor_decay)\n",
    "    twopoint_h2es = stick_breaking(twopoint_ratio)\n",
    "    twopoint_h2es_old = stick_breaking(twopoint_ratio_old)\n",
    "    wts_twopoint = np.sqrt(np.maximum(0., twopoint_h2es * probs))\n",
    "\n",
    "    # Other weights: lvdl(constant allocation rate), propscore and uniform\n",
    "    wts_lvdl = np.sqrt(probs)\n",
    "    wts_propscore = probs\n",
    "    wts_uniform = np.ones_like(probs)\n",
    "\n",
    "    \"\"\" Estimate arm values \"\"\"\n",
    "    # for each weighting scheme, return [estimate, S.E, bias, 90%-coverage, t-stat, mse, truth]\n",
    "    stats = dict(\n",
    "        uniform=evaluate_aipw_stats(scores, wts_uniform, truth),\n",
    "        propscore=evaluate_aipw_stats(scores, wts_propscore, truth),\n",
    "        lvdl=evaluate_aipw_stats(scores, wts_lvdl, truth),\n",
    "        two_point=evaluate_aipw_stats(scores, wts_twopoint, truth),\n",
    "        beta_bernoulli=evaluate_beta_bernoulli_stats(rewards, arms, truth, K, floor_decay, alpha=.1),\n",
    "        gamma_exponential=evaluate_gamma_exponential_stats(rewards, arms, truth, K, floor_decay, c=2, expected_noise_variance=1/3, alpha=.1),\n",
    "        sample_mean_naive=evaluate_sample_mean_naive_stats(rewards, arms, truth, K, alpha=.1)\n",
    "    )\n",
    "    \n",
    "    # # add estimates of W_decorrelation\n",
    "    W_name = f'wdecorr_results/W_lambdas_{experiment}-{noise_func}-{T}-{floor_decay}.npz'\n",
    "    try:\n",
    "        W_save = np.load(W_name)  # load presaved W-lambdas\n",
    "        for percentile, W_lambda in zip(W_save['percentiles'], W_save['W_lambdas']):\n",
    "            stats[f'W-decorrelation_{percentile}'] = wdecorr_stats(arms, rewards, K, W_lambda, truth)\n",
    "    except FileNotFoundError:\n",
    "        print(f'Could not find relevant w-decorrelation file {W_name}.')\n",
    "        \n",
    "    \n",
    "    \"\"\" Estimate contrasts \"\"\"\n",
    "    contrasts = dict(\n",
    "        uniform=evaluate_aipw_contrasts(scores, wts_uniform, truth),\n",
    "        propscore=evaluate_aipw_contrasts(scores, wts_propscore, truth),\n",
    "        lvdl=evaluate_aipw_contrasts(scores, wts_lvdl, truth),\n",
    "        two_point=evaluate_aipw_contrasts(scores, wts_twopoint, truth),\n",
    "        beta_bernoulli=evaluate_beta_bernoulli_contrasts(rewards, arms, truth, K, floor_decay, alpha=.1),\n",
    "        gamma_exponential=evaluate_gamma_exponential_contrasts(rewards, arms, truth, K, floor_decay, c=2, expected_noise_variance=1/3, alpha=.1),\n",
    "        sample_mean_naive=evaluate_sample_mean_naive_contrasts(rewards, arms, truth, K, alpha=.1)\n",
    "    )\n",
    "\n",
    "    \n",
    "    \"\"\" Save results \"\"\"\n",
    "    config = dict(\n",
    "        T=T,\n",
    "        K=K,\n",
    "        noise_func=noise_func,\n",
    "        noise_scale=noise_scale,\n",
    "        floor_start=floor_start,\n",
    "        floor_decay=floor_decay,\n",
    "        initial=initial,\n",
    "        dgp=experiment,\n",
    "    )\n",
    "\n",
    "    ratios = dict(\n",
    "        lvdl=np.ones((T, K)) / np.arange(T, 0, -1)[:, np.newaxis],\n",
    "        two_point=twopoint_ratio,\n",
    "    )\n",
    "    \n",
    "    # save lambda values at selected timepoints\n",
    "    saved_timepoints = list(range(0, T, T // 250)) + [T-1]\n",
    "    for ratio in ratios:\n",
    "        ratios[ratio] = ratios[ratio][saved_timepoints, :]\n",
    "    \n",
    "    # tabulate arm values\n",
    "    tabs_stats = []\n",
    "    for method, stat in stats.items():\n",
    "        tab_stats = pd.DataFrame({\"statistic\": [\"estimate\", \"stderr\", \"bias\", \"90% coverage of t-stat\", \"t-stat\", \"mse\", \"CI_width\", \"truth\"] * stat.shape[1],\n",
    "                                  \"policy\": np.repeat(np.arange(K), stat.shape[0]),\n",
    "                                  \"value\":  stat.flatten(order='F'),\n",
    "                                  \"method\": method,\n",
    "                                 **config})\n",
    "        tabs_stats.append(tab_stats)\n",
    "\n",
    "\n",
    "    # tabulate arm contrasts\n",
    "    tabs_contrasts = []\n",
    "    for method, contrast in contrasts.items():\n",
    "        tabs_contrast = pd.DataFrame({\"statistic\": [\"estimate\", \"stderr\", \"bias\", \"90% coverage of t-stat\", \"t-stat\", \"mse\", \"CI_width\", \"truth\"] * contrast.shape[1],\n",
    "                                      \"policy\": np.repeat([f\"(0,{k})\" for k in np.arange(1, K)], contrast.shape[0]),\n",
    "                                      \"value\": contrast.flatten(order='F'),\n",
    "                                      \"method\": method,\n",
    "                                     **config})\n",
    "        tabs_contrasts.append(tabs_contrast)\n",
    "\n",
    "    \n",
    "    df_stats.extend(tabs_stats)\n",
    "    df_stats.extend(tabs_contrasts)\n",
    "    \n",
    "    \n",
    "    \"\"\" Save relevant lambda weights, if applicable \"\"\"\n",
    "    if T == max(Ts):\n",
    "        saved_timepoints = list(range(0, T, T // 500))\n",
    "        lambdas = twopoint_ratio[saved_timepoints] * (T - np.array(saved_timepoints)[:,np.newaxis])\n",
    "        lambdas = {key: value for key, value in enumerate(lambdas.T)}\n",
    "        dfl = pd.DataFrame({**lambdas, **config, 'time': saved_timepoints})\n",
    "        dfl = pd.melt(dfl, id_vars=list(config.keys()) + ['time'], var_name='policy', value_vars=list(range(K)))\n",
    "        df_lambdas.append(dfl)\n",
    "        \n",
    "    print(f\"Time passed {time()-start_time}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        sample_mean_naive=evaluate_sample_mean_naive_contrasts(rewards, arms, truth, K, alpha=.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f9ba952eb10a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_lambdas\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdf_lambdas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_lambdas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m     )\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "df_stats = pd.concat(df_stats)\n",
    "if len(df_lambdas) > 0:\n",
    "    df_lambdas = pd.concat(df_lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if on_sherlock():\n",
    "    write_dir = get_sherlock_dir('adaptive-confidence-intervals', 'simulations', create=True)\n",
    "    print(f\"saving at {write_dir}\")\n",
    "else:\n",
    "     write_dir = join(os.getcwd(), 'results')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving information about contrasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filename1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-16ecdfbc2edb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilename_contrast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompose_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'contrast'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwrite_path1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m df_contrast = df_stats.query(\n\u001b[1;32m      5\u001b[0m             \u001b[0;34m'policy == \"(0,2)\" and '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filename1' is not defined"
     ]
    }
   ],
   "source": [
    "filename_contrast = compose_filename(f'contrast', 'pkl')\n",
    "write_path_contrast = os.path.join(write_dir, filename_contrast)\n",
    "\n",
    "df_contrast = df_stats.query(\n",
    "            'policy == \"(0,2)\" and '\n",
    "            'statistic == [\"mse\", \"bias\", \"90% coverage of t-stat\", \"CI_width\"] and '\n",
    "            \"method == ['uniform', 'lvdl', 'two_point',  'sample_mean_naive', 'gamma_exponential', 'W-decorrelation_15']\")\n",
    "df_contrast.to_pickle(write_path_contrast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save information about arms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e6e42c3fdb32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mwrite_path_arms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_contrast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m df_contrast = df_stats.query(\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0;34m'policy == [0, 1, 2] and '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;34m'statistic == [\"mse\", \"bias\", \"90% coverage of t-stat\", \"CI_width\"] and '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_stats' is not defined"
     ]
    }
   ],
   "source": [
    "filename_contrast = compose_filename(f'arm', 'pkl')\n",
    "write_path_arms = os.path.join(write_dir, filename_contrast)\n",
    "\n",
    "df_contrast = df_stats.query(\n",
    "            'policy == [0, 1, 2] and '\n",
    "            'statistic == [\"mse\", \"bias\", \"90% coverage of t-stat\", \"CI_width\"] and '\n",
    "            \"method == ['uniform', 'lvdl', 'two_point',  'sample_mean_naive', 'gamma_exponential', 'W-decorrelation_15']\")\n",
    "df_contrast.to_pickle(write_path_contrast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save information about $\\lambda$ behavior, if appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename2 = compose_filename(f'lambdas', 'pkl')\n",
    "write_path2 = os.path.join(write_dir, filename2)\n",
    "df_stats = pd.concat(df_stats)\n",
    "if len(df_lambdas) > 0:\n",
    "    df_lambdas = pd.concat(df_lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done.\n"
     ]
    }
   ],
   "source": [
    "print(\"All done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
