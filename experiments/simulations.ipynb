{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script runs simulations reported in our paper Confidence Intervals for Policy Evaluation in Adaptive Experiments (https://arxiv.org/abs/1911.02768)\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "# sys.path.insert(0, \"/home/rhzhan/adaptive-confidence-intervals/\")\n",
    "from time import time\n",
    "from sys import argv\n",
    "from random import choice\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from adaptive_CI.experiments import run_mab_experiment\n",
    "from adaptive_CI.compute import stick_breaking\n",
    "from adaptive_CI.saving import *\n",
    "from adaptive_CI.inference import *\n",
    "from adaptive_CI.weights import *\n",
    "\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulation 10/20000\n",
      "Running simulation 20/20000\n",
      "Running simulation 30/20000\n",
      "Running simulation 40/20000\n",
      "Running simulation 50/20000\n",
      "Running simulation 60/20000\n",
      "Running simulation 70/20000\n",
      "Running simulation 80/20000\n",
      "Running simulation 90/20000\n",
      "Running simulation 100/20000\n",
      "Running simulation 110/20000\n",
      "Running simulation 120/20000\n",
      "Running simulation 130/20000\n",
      "Running simulation 140/20000\n",
      "Running simulation 150/20000\n",
      "Running simulation 160/20000\n",
      "Running simulation 170/20000\n",
      "Running simulation 180/20000\n",
      "Running simulation 190/20000\n",
      "Running simulation 200/20000\n",
      "Running simulation 210/20000\n",
      "Running simulation 220/20000\n",
      "Running simulation 230/20000\n",
      "Running simulation 240/20000\n",
      "Running simulation 250/20000\n",
      "Running simulation 260/20000\n",
      "Running simulation 270/20000\n",
      "Running simulation 280/20000\n",
      "Running simulation 290/20000\n",
      "Running simulation 300/20000\n",
      "Running simulation 310/20000\n",
      "Running simulation 320/20000\n",
      "Running simulation 330/20000\n",
      "Running simulation 340/20000\n",
      "Running simulation 350/20000\n",
      "Running simulation 360/20000\n",
      "Running simulation 370/20000\n",
      "Running simulation 380/20000\n",
      "Running simulation 390/20000\n",
      "Running simulation 400/20000\n",
      "Running simulation 410/20000\n",
      "Running simulation 420/20000\n",
      "Running simulation 430/20000\n",
      "Running simulation 440/20000\n",
      "Running simulation 450/20000\n",
      "Running simulation 460/20000\n",
      "Running simulation 470/20000\n",
      "Running simulation 480/20000\n",
      "Running simulation 490/20000\n",
      "Running simulation 500/20000\n",
      "Running simulation 510/20000\n",
      "Running simulation 520/20000\n",
      "Running simulation 530/20000\n",
      "Running simulation 540/20000\n",
      "Running simulation 550/20000\n",
      "Running simulation 560/20000\n",
      "Running simulation 570/20000\n",
      "Running simulation 580/20000\n",
      "Running simulation 590/20000\n",
      "Running simulation 600/20000\n",
      "Running simulation 610/20000\n",
      "Running simulation 620/20000\n",
      "Running simulation 630/20000\n",
      "Running simulation 640/20000\n",
      "Running simulation 650/20000\n",
      "Running simulation 660/20000\n",
      "Running simulation 670/20000\n",
      "Running simulation 680/20000\n",
      "Running simulation 690/20000\n",
      "Running simulation 700/20000\n",
      "Running simulation 710/20000\n",
      "Running simulation 720/20000\n",
      "Running simulation 730/20000\n",
      "Running simulation 740/20000\n",
      "Running simulation 750/20000\n",
      "Running simulation 760/20000\n",
      "Running simulation 770/20000\n",
      "Running simulation 780/20000\n",
      "Running simulation 790/20000\n",
      "Running simulation 800/20000\n",
      "Running simulation 810/20000\n",
      "Running simulation 820/20000\n",
      "Running simulation 830/20000\n",
      "Running simulation 840/20000\n",
      "Running simulation 850/20000\n",
      "Running simulation 860/20000\n",
      "Running simulation 870/20000\n",
      "Running simulation 880/20000\n",
      "Running simulation 890/20000\n",
      "Running simulation 900/20000\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------\n",
    "num_sims = 20000\n",
    "\n",
    "# Read DGP specification\n",
    "noise_func = 'uniform'\n",
    "truths = {\n",
    "    'nosignal': np.array([1., 1., 1.]),\n",
    "    'lowSNR': np.array([.9, 1., 1.1]),\n",
    "    'highSNR': np.array([.5, 1., 1.5])\n",
    "}\n",
    "\n",
    "results_list = []\n",
    "start_time = time()\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Run simulations\n",
    "for s in range(num_sims):\n",
    "    if (s+1) % 10 == 0:\n",
    "        print(f'Running simulation {s+1}/{num_sims}')\n",
    "\n",
    "    \"\"\" Experiment configuration \"\"\"\n",
    "    experiment = choice(['nosignal', 'lowSNR', 'highSNR'])\n",
    "    truth = truths[experiment]\n",
    "    T = choice([1000, 5000, 10000, 20000])  # number of samples\n",
    "    K = len(truth)  # number of arms\n",
    "    initial = 5  # initial number of samples of each arm to do pure exploration\n",
    "    floor_start = 1 / K\n",
    "    floor_decay = 0.9\n",
    "    exploration = 'TS'\n",
    "    noise_scale = 1.0\n",
    "\n",
    "    \"\"\" Generate data \"\"\"\n",
    "    if noise_func == 'uniform':\n",
    "        noise = np.random.uniform(-noise_scale, noise_scale, size=(T, K))\n",
    "    else:\n",
    "        noise = np.random.exponential(noise_scale, size=(T, K)) - noise_scale\n",
    "    ys = truth + noise\n",
    "\n",
    "    \"\"\" Run experiment \"\"\"\n",
    "    data = run_mab_experiment(\n",
    "        ys,\n",
    "        initial=initial,\n",
    "        floor_start=floor_start,\n",
    "        floor_decay=floor_decay,\n",
    "        exploration=exploration)\n",
    "\n",
    "    probs = data['probs']\n",
    "    rewards = data['rewards']\n",
    "    arms = data['arms']\n",
    "\n",
    "    \"\"\" Compute AIPW scores \"\"\"\n",
    "    muhat = np.row_stack([np.zeros(K), sample_mean(rewards, arms, K)[:-1]])\n",
    "    scores = aw_scores(rewards, arms, probs, muhat)\n",
    "\n",
    "    \"\"\" Compute weights \"\"\"\n",
    "    # Two-point allocation rate\n",
    "    twopoint_ratio = twopoint_stable_var_ratio(probs, floor_decay)\n",
    "    twopoint_h2es = stick_breaking(twopoint_ratio)\n",
    "    wts_twopoint = np.sqrt(np.maximum(0., twopoint_h2es * probs))\n",
    "\n",
    "    # Other weights: lvdl(constant allocation rate), propscore and uniform\n",
    "    wts_lvdl = np.sqrt(probs)\n",
    "    wts_propscore = probs\n",
    "    wts_uniform = np.ones_like(probs)\n",
    "\n",
    "    \"\"\" Estimate arm values \"\"\"\n",
    "    # for each weighting scheme, return [estimate, S.E, bias, 95%-coverage, t-stat, mse, truth]\n",
    "    stats = dict(\n",
    "        uniform=aw_stats(scores, wts_uniform, truth),\n",
    "        propscore=aw_stats(scores, wts_propscore, truth),\n",
    "        lvdl=aw_stats(scores, wts_lvdl, truth),\n",
    "        two_point=aw_stats(scores, wts_twopoint, truth),\n",
    "    )\n",
    "\n",
    "    \"\"\" Estimate contrasts \"\"\"\n",
    "    contrasts = dict(\n",
    "        uniform=aw_contrasts(scores, wts_uniform, truth),\n",
    "        propscore=aw_contrasts(scores, wts_propscore, truth),\n",
    "        lvdl=aw_contrasts(scores, wts_lvdl, truth),\n",
    "        two_point=aw_contrasts(scores, wts_twopoint, truth),\n",
    "    )\n",
    "\n",
    "    \"\"\" Save results \"\"\"\n",
    "    weights = dict(\n",
    "        uniform=wts_uniform,\n",
    "        propscore=wts_propscore,\n",
    "        lvdl=wts_lvdl,\n",
    "        two_point=wts_twopoint,\n",
    "    )\n",
    "\n",
    "    ratios = dict(\n",
    "        lvdl=np.ones((T, K)) / np.arange(T, 0, -1)[:, np.newaxis],\n",
    "        two_point=twopoint_ratio,\n",
    "    )\n",
    "\n",
    "    config = dict(\n",
    "        T=T,\n",
    "        K=K,\n",
    "        noise_func=noise_func,\n",
    "        noise_scale=noise_scale,\n",
    "        floor_start=floor_start,\n",
    "        floor_decay=floor_decay,\n",
    "        initial=initial,\n",
    "        truth=truth,\n",
    "    )\n",
    "\n",
    "    # only save at saved_timepoints for assigmnment probabilities, conditional variance, weights, ratios(lambdas)\n",
    "    saved_timepoints = list(range(0, T, T // 100))\n",
    "    condVars = dict()\n",
    "    for method, weight in weights.items():\n",
    "        condVar = weight ** 2 / probs / np.sum(weight, 0) ** 2 * T\n",
    "        weight = weight / np.sum(weight, 0) * T\n",
    "        condVars[method] = condVar[saved_timepoints, :]\n",
    "        weights[method] = weight[saved_timepoints, :]\n",
    "    for ratio in ratios:\n",
    "        ratios[ratio] = ratios[ratio][saved_timepoints, :]\n",
    "    probs = probs[saved_timepoints, :]\n",
    "    results = dict(\n",
    "        config=config,\n",
    "        probs=probs,\n",
    "        stats=stats,\n",
    "        contrasts=contrasts,\n",
    "        weights=weights,\n",
    "        ratios=ratios,\n",
    "        condVars=condVars)\n",
    "\n",
    "    results_list.append(results)\n",
    "\n",
    "    write_dir = os.path.join(os.getcwd(), 'results')\n",
    "    if not os.path.exists(write_dir):\n",
    "        os.makedirs(write_dir)\n",
    "    filename = compose_filename(f'weight_experiment_{experiment}_{noise_func}', 'pkl')\n",
    "    write_path = os.path.join(write_dir, filename)\n",
    "    with open(write_path, \"wb\") as f:\n",
    "        pickle.dump(results_list, f)\n",
    "    # print(filename)\n",
    "\n",
    "    results_list = []\n",
    "\n",
    "print(f\"Time passed {time()-start_time}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
