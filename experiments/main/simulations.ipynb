{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation for non-contextual settings\n",
    "We adjusted the simulation file provided by [Hadad, Vitor, et al. (2021)](https://arxiv.org/abs/1911.02768) to only contains the methods of interest in our banditsCI package: uniform and two-point.\n",
    "\n",
    "The original simulation code provided by [Hadad, Vitor, et al. (2021)](https://arxiv.org/abs/1911.02768) can be accessed [here](https://github.com/gsbDBI/adaptive-confidence-intervals/blob/master/experiments/main/simulations.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from time import time\n",
    "from sys import argv\n",
    "from random import choice\n",
    "from time import time\n",
    "from os.path import dirname, realpath, join, exists\n",
    "from os import makedirs, chmod\n",
    "from getpass import getuser\n",
    "\n",
    "from adaptive_CI.experiments import run_mab_experiment\n",
    "from adaptive_CI.compute import stick_breaking\n",
    "from adaptive_CI.inference import *\n",
    "from adaptive_CI.weights import *\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_sherlock():\n",
    "    \"\"\" \n",
    "    Note: This can be ignored by non-Stanford members.\n",
    "\n",
    "    Checks if running on Stanford's Sherlock cluster\n",
    "    \"\"\"\n",
    "    return 'GROUP_SCRATCH' in os.environ\n",
    "\n",
    "\n",
    "def get_sherlock_dir(project, *tail, create=True):\n",
    "    \"\"\"\n",
    "    Note: This can be ignored by non-Stanford members.\n",
    "    \n",
    "    Output consistent folder name in Sherlock.\n",
    "    If create=True and on Sherlock, also makes folder with group permissions.\n",
    "    If create=True and not on Sherlock, does not create anything.\n",
    "\n",
    "    '/scratch/groups/athey/username/project/tail1/tail2/.../tailn'.\n",
    "\n",
    "    >>> get_sherlock_dir('adaptive-inference')\n",
    "    '/scratch/groups/athey/adaptive-inference/vitorh'\n",
    "\n",
    "    >>> get_sherlock_dir('toronto')\n",
    "    '/scratch/groups/athey/toronto/vitorh/'\n",
    "\n",
    "    >>> get_sherlock_dir('adaptive-inference', 'experiments', 'exp_out')\n",
    "    '/scratch/groups/athey/adaptive-inference/vitorh/experiments/exp_out'\n",
    "    \"\"\"\n",
    "    base = join(\"/\", \"scratch\", \"groups\", \"athey\", project, getuser())\n",
    "    path = join(base, *tail)\n",
    "    if not exists(path) and create and on_sherlock():\n",
    "        makedirs(path, exist_ok=True)\n",
    "        # Correct permissions for the whole directory branch\n",
    "        chmod_path = base\n",
    "        chmod(base, 0o775)\n",
    "        for child in tail:\n",
    "            chmod_path = join(chmod_path, child)\n",
    "            chmod(chmod_path, 0o775)\n",
    "    return path\n",
    "\n",
    "\n",
    "def compose_filename(prefix, extension):\n",
    "    \"\"\"\n",
    "    Creates a unique filename based on Github commit id and time.\n",
    "    Useful when running in parallel on server.\n",
    "\n",
    "    INPUT:\n",
    "        - prefix: file name prefix\n",
    "        - extension: file extension\n",
    "\n",
    "    OUTPUT:\n",
    "        - fname: unique filename\n",
    "    \"\"\"\n",
    "    # Tries to find a commit hash\n",
    "    try:\n",
    "        commit = subprocess\\\n",
    "            .check_output(['git', 'rev-parse', '--short', 'HEAD'],\n",
    "                          stderr=subprocess.DEVNULL)\\\n",
    "            .strip()\\\n",
    "            .decode('ascii')\n",
    "    except subprocess.CalledProcessError:\n",
    "        commit = ''\n",
    "\n",
    "    # Other unique identifiers\n",
    "    rnd = str(int(time() * 1e8 % 1e8))\n",
    "    sid = tid = jid = ''\n",
    "    ident = filter(None, [prefix, commit, jid, sid, tid, rnd])\n",
    "    basename = \"_\".join(ident)\n",
    "    fname = f\"{basename}.{extension}\"\n",
    "    return fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sims = 200 if on_sherlock() else 1\n",
    "\n",
    "# DGP specification\n",
    "# ----------------------------------------------------\n",
    "noise_func = 'uniform'\n",
    "truths = {\n",
    "    'nosignal': np.array([1., 1., 1.]),\n",
    "    'lowSNR': np.array([.9, 1., 1.1]),\n",
    "    'highSNR': np.array([.5, 1., 1.5])\n",
    "}\n",
    "# if on_sherlock():\n",
    "#     Ts = [1_000, 5_000, 10_000, 50_000, 100_000]\n",
    "# else:\n",
    "#     Ts = [5_000]\n",
    "# Setting Ts to always be [5000] regardless of the environment\n",
    "Ts = [5_000]\n",
    "floor_decays = [.7]\n",
    "initial = 5  # initial number of samples of each arm to do pure exploration\n",
    "exploration = 'TS'\n",
    "noise_scale = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = []\n",
    "df_lambdas = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time passed 0.4108390808105469s\n"
     ]
    }
   ],
   "source": [
    "# Run simulations\n",
    "for s in range(num_sims):\n",
    "    if (s+1) % 10 == 0:\n",
    "        print(f'Running simulation {s+1}/{num_sims}')\n",
    "\n",
    "    \"\"\" Experiment configuration \"\"\"\n",
    "    T = choice(Ts)  # number of samples\n",
    "    experiment = choice(list(truths.keys()))\n",
    "    truth = truths[experiment]\n",
    "    K = len(truth)  # number of arms\n",
    "    floor_start = 1/K\n",
    "    floor_decay = choice(floor_decays)\n",
    "\n",
    "    \"\"\" Generate data \"\"\"\n",
    "    noise = np.random.uniform(-noise_scale, noise_scale, size=(T, K))\n",
    "    ys = truth + noise\n",
    "\n",
    "    \"\"\" Run experiment \"\"\"\n",
    "    data = run_mab_experiment(\n",
    "        ys,\n",
    "        initial=initial,\n",
    "        floor_start=floor_start,\n",
    "        floor_decay=floor_decay,\n",
    "        exploration=exploration)\n",
    "\n",
    "    probs = data['probs']\n",
    "    rewards = data['rewards']\n",
    "    arms = data['arms']\n",
    "\n",
    "    \"\"\" Compute AIPW scores \"\"\"\n",
    "    muhat = np.row_stack([np.zeros(K), sample_mean(rewards, arms, K)[:-1]])\n",
    "    scores = aw_scores(rewards, arms, probs, muhat)\n",
    "\n",
    "    \"\"\" Compute weights \"\"\"\n",
    "    # Two-point allocation rate\n",
    "    twopoint_ratio = twopoint_stable_var_ratio(e=probs, alpha=floor_decay)\n",
    "    twopoint_ratio_old = twopoint_stable_var_ratio_old(probs, floor_start, floor_decay)\n",
    "    twopoint_h2es = stick_breaking(twopoint_ratio)\n",
    "    twopoint_h2es_old = stick_breaking(twopoint_ratio_old)\n",
    "    wts_twopoint = np.sqrt(np.maximum(0., twopoint_h2es * probs))\n",
    "\n",
    "    # Other weights: lvdl(constant allocation rate), propscore and uniform\n",
    "    wts_lvdl = np.sqrt(probs)\n",
    "    wts_propscore = probs\n",
    "    wts_uniform = np.ones_like(probs)\n",
    "\n",
    "    \"\"\" Estimate arm values \"\"\"\n",
    "    # for each weighting scheme, return [estimate, S.E, bias, 90%-coverage, t-stat, mse, truth]\n",
    "    stats = dict(\n",
    "        uniform=evaluate_aipw_stats(scores, wts_uniform, truth),\n",
    "        propscore=evaluate_aipw_stats(scores, wts_propscore, truth),\n",
    "        lvdl=evaluate_aipw_stats(scores, wts_lvdl, truth),\n",
    "        two_point=evaluate_aipw_stats(scores, wts_twopoint, truth),\n",
    "        beta_bernoulli=evaluate_beta_bernoulli_stats(rewards, arms, truth, K, floor_decay, alpha=.1),\n",
    "        gamma_exponential=evaluate_gamma_exponential_stats(rewards, arms, truth, K, floor_decay, c=2, expected_noise_variance=1/3, alpha=.1),\n",
    "        sample_mean_naive=evaluate_sample_mean_naive_stats(rewards, arms, truth, K, alpha=.1)\n",
    "    )\n",
    "    \n",
    "    # # add estimates of W_decorrelation\n",
    "    W_name = f'wdecorr_results/W_lambdas_{experiment}-{noise_func}-{T}-{floor_decay}.npz'\n",
    "    try:\n",
    "        W_save = np.load(W_name)  # load presaved W-lambdas\n",
    "        for percentile, W_lambda in zip(W_save['percentiles'], W_save['W_lambdas']):\n",
    "            stats[f'W-decorrelation_{percentile}'] = wdecorr_stats(arms, rewards, K, W_lambda, truth)\n",
    "    except FileNotFoundError:\n",
    "        print(f'Could not find relevant w-decorrelation file {W_name}. Ignoring.')\n",
    "        \n",
    "    \n",
    "    \"\"\" Estimate contrasts \"\"\"\n",
    "    contrasts = dict(\n",
    "        uniform=evaluate_aipw_contrasts(scores, wts_uniform, truth),\n",
    "        propscore=evaluate_aipw_contrasts(scores, wts_propscore, truth),\n",
    "        lvdl=evaluate_aipw_contrasts(scores, wts_lvdl, truth),\n",
    "        two_point=evaluate_aipw_contrasts(scores, wts_twopoint, truth),\n",
    "        beta_bernoulli=evaluate_beta_bernoulli_contrasts(rewards, arms, truth, K, floor_decay, alpha=.1),\n",
    "        gamma_exponential=evaluate_gamma_exponential_contrasts(rewards, arms, truth, K, floor_decay, c=2, expected_noise_variance=1/3, alpha=.1),\n",
    "        sample_mean_naive=evaluate_sample_mean_naive_contrasts(rewards, arms, truth, K, alpha=.1)\n",
    "    )\n",
    "# have a look at `contrast` dataframe\n",
    "#     print(contrasts)\n",
    "    \n",
    "    \"\"\" Save results \"\"\"\n",
    "    config = dict(\n",
    "        T=T,\n",
    "        K=K,\n",
    "        noise_func=noise_func,\n",
    "        noise_scale=noise_scale,\n",
    "        floor_start=floor_start,\n",
    "        floor_decay=floor_decay,\n",
    "        initial=initial,\n",
    "        dgp=experiment,\n",
    "    )\n",
    "\n",
    "    ratios = dict(\n",
    "        lvdl=np.ones((T, K)) / np.arange(T, 0, -1)[:, np.newaxis],\n",
    "        two_point=twopoint_ratio,\n",
    "    )\n",
    "    \n",
    "    # save lambda values at selected timepoints\n",
    "    saved_timepoints = list(range(0, T, T // 250)) + [T-1]\n",
    "    for ratio in ratios:\n",
    "        ratios[ratio] = ratios[ratio][saved_timepoints, :]\n",
    "    \n",
    "    # tabulate arm values\n",
    "    tabs_stats = []\n",
    "    for method, stat in stats.items():\n",
    "        tab_stats = pd.DataFrame({\"statistic\": [\"estimate\", \"stderr\", \"bias\", \"90% coverage of t-stat\", \"t-stat\", \"mse\", \"CI_width\", \"truth\"] * stat.shape[1],\n",
    "                                  \"policy\": np.repeat(np.arange(K), stat.shape[0]),\n",
    "                                  \"value\":  stat.flatten(order='F'),\n",
    "                                  \"method\": method,\n",
    "                                 **config})\n",
    "        tabs_stats.append(tab_stats)\n",
    "\n",
    "\n",
    "    # tabulate arm contrasts\n",
    "    tabs_contrasts = []\n",
    "    for method, contrast in contrasts.items():\n",
    "        tabs_contrast = pd.DataFrame({\"statistic\": [\"estimate\", \"stderr\", \"bias\", \"90% coverage of t-stat\", \"t-stat\", \"mse\", \"CI_width\", \"truth\"] * contrast.shape[1],\n",
    "                                      \"policy\": np.repeat([f\"(0,{k})\" for k in np.arange(1, K)], contrast.shape[0]),\n",
    "                                      \"value\": contrast.flatten(order='F'),\n",
    "                                      \"method\": method,\n",
    "                                     **config})\n",
    "        tabs_contrasts.append(tabs_contrast)\n",
    "\n",
    "    \n",
    "    df_stats.extend(tabs_stats)\n",
    "    df_stats.extend(tabs_contrasts)\n",
    "    \n",
    "    \n",
    "    \"\"\" Save relevant lambda weights, if applicable \"\"\"\n",
    "    if T == max(Ts):\n",
    "        saved_timepoints = list(range(0, T, T // 500))\n",
    "        lambdas = twopoint_ratio[saved_timepoints] * (T - np.array(saved_timepoints)[:,np.newaxis])\n",
    "        lambdas = {key: value for key, value in enumerate(lambdas.T)}\n",
    "        dfl = pd.DataFrame({**lambdas, **config, 'time': saved_timepoints})\n",
    "        dfl = pd.melt(dfl, id_vars=list(config.keys()) + ['time'], var_name='policy', value_vars=list(range(K)))\n",
    "        df_lambdas.append(dfl)\n",
    "        \n",
    "    print(f\"Time passed {time()-start_time}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uniform': array([[-2.70201475e-02, -1.31118086e-02],\n",
      "       [ 3.11843254e-02,  4.40751541e-02],\n",
      "       [-2.70201475e-02, -1.31118086e-02],\n",
      "       [ 1.00000000e+00,  1.00000000e+00],\n",
      "       [-8.66465672e-01, -2.97487526e-01],\n",
      "       [ 7.30088371e-04,  1.71919524e-04],\n",
      "       [ 5.12936508e-02,  7.24971771e-02],\n",
      "       [ 0.00000000e+00,  0.00000000e+00]]), 'propscore': array([[-2.18168565e-02,  1.42442907e-02],\n",
      "       [ 2.74873445e-02,  3.58223267e-02],\n",
      "       [-2.18168565e-02,  1.42442907e-02],\n",
      "       [ 1.00000000e+00,  1.00000000e+00],\n",
      "       [-7.93705498e-01,  3.97637228e-01],\n",
      "       [ 4.75975227e-04,  2.02899817e-04],\n",
      "       [ 4.52126584e-02,  5.89224839e-02],\n",
      "       [ 0.00000000e+00,  0.00000000e+00]]), 'lvdl': array([[-2.33340350e-02,  1.49392867e-03],\n",
      "       [ 2.87489243e-02,  3.84928283e-02],\n",
      "       [-2.33340350e-02,  1.49392867e-03],\n",
      "       [ 1.00000000e+00,  1.00000000e+00],\n",
      "       [-8.11648977e-01,  3.88105716e-02],\n",
      "       [ 5.44477189e-04,  2.23182286e-06],\n",
      "       [ 4.72877724e-02,  6.33150682e-02],\n",
      "       [ 0.00000000e+00,  0.00000000e+00]]), 'two_point': array([[-2.77210858e-02,  8.56467511e-03],\n",
      "       [ 3.07141044e-02,  4.56001959e-02],\n",
      "       [-2.77210858e-02,  8.56467511e-03],\n",
      "       [ 1.00000000e+00,  1.00000000e+00],\n",
      "       [-9.02552308e-01,  1.87821016e-01],\n",
      "       [ 7.68458600e-04,  7.33536598e-05],\n",
      "       [ 5.05202061e-02,  7.50056476e-02],\n",
      "       [ 0.00000000e+00,  0.00000000e+00]]), 'beta_bernoulli': array([[-2.21089192e-02,  1.37494650e-02],\n",
      "       [ 2.60725961e-02,  3.45443779e-02],\n",
      "       [-2.21089192e-02,  1.37494650e-02],\n",
      "       [ 1.00000000e+00,  1.00000000e+00],\n",
      "       [-8.47975367e-01,  3.98023233e-01],\n",
      "       [ 4.88804309e-04,  1.89047787e-04],\n",
      "       [ 2.33223720e-01,  3.34108351e-01],\n",
      "       [ 0.00000000e+00,  0.00000000e+00]]), 'gamma_exponential': array([[-2.21089192e-02,  1.37494650e-02],\n",
      "       [ 2.60725961e-02,  3.45443779e-02],\n",
      "       [-2.21089192e-02,  1.37494650e-02],\n",
      "       [ 1.00000000e+00,  1.00000000e+00],\n",
      "       [-8.47975367e-01,  3.98023233e-01],\n",
      "       [ 4.88804309e-04,  1.89047787e-04],\n",
      "       [ 1.46518892e-01,  2.15642363e-01],\n",
      "       [ 0.00000000e+00,  0.00000000e+00]]), 'sample_mean_naive': array([[-2.21089192e-02,  1.37494650e-02],\n",
      "       [ 2.60725961e-02,  3.45443779e-02],\n",
      "       [-2.21089192e-02,  1.37494650e-02],\n",
      "       [ 1.00000000e+00,  1.00000000e+00],\n",
      "       [-8.47975367e-01,  3.98023233e-01],\n",
      "       [ 4.88804309e-04,  1.89047787e-04],\n",
      "       [ 4.28856042e-02,  5.68204453e-02],\n",
      "       [ 0.00000000e+00,  0.00000000e+00]])}\n"
     ]
    }
   ],
   "source": [
    "print(contrasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                 statistic policy     value   method     T  K noise_func  \\\n",
       " 0                 estimate  (0,1) -0.027020  uniform  5000  3    uniform   \n",
       " 1                   stderr  (0,1)  0.031184  uniform  5000  3    uniform   \n",
       " 2                     bias  (0,1) -0.027020  uniform  5000  3    uniform   \n",
       " 3   90% coverage of t-stat  (0,1)  1.000000  uniform  5000  3    uniform   \n",
       " 4                   t-stat  (0,1) -0.866466  uniform  5000  3    uniform   \n",
       " 5                      mse  (0,1)  0.000730  uniform  5000  3    uniform   \n",
       " 6                 CI_width  (0,1)  0.051294  uniform  5000  3    uniform   \n",
       " 7                    truth  (0,1)  0.000000  uniform  5000  3    uniform   \n",
       " 8                 estimate  (0,2) -0.013112  uniform  5000  3    uniform   \n",
       " 9                   stderr  (0,2)  0.044075  uniform  5000  3    uniform   \n",
       " 10                    bias  (0,2) -0.013112  uniform  5000  3    uniform   \n",
       " 11  90% coverage of t-stat  (0,2)  1.000000  uniform  5000  3    uniform   \n",
       " 12                  t-stat  (0,2) -0.297488  uniform  5000  3    uniform   \n",
       " 13                     mse  (0,2)  0.000172  uniform  5000  3    uniform   \n",
       " 14                CI_width  (0,2)  0.072497  uniform  5000  3    uniform   \n",
       " 15                   truth  (0,2)  0.000000  uniform  5000  3    uniform   \n",
       " \n",
       "     noise_scale  floor_start  floor_decay  initial       dgp  \n",
       " 0           1.0     0.333333          0.7        5  nosignal  \n",
       " 1           1.0     0.333333          0.7        5  nosignal  \n",
       " 2           1.0     0.333333          0.7        5  nosignal  \n",
       " 3           1.0     0.333333          0.7        5  nosignal  \n",
       " 4           1.0     0.333333          0.7        5  nosignal  \n",
       " 5           1.0     0.333333          0.7        5  nosignal  \n",
       " 6           1.0     0.333333          0.7        5  nosignal  \n",
       " 7           1.0     0.333333          0.7        5  nosignal  \n",
       " 8           1.0     0.333333          0.7        5  nosignal  \n",
       " 9           1.0     0.333333          0.7        5  nosignal  \n",
       " 10          1.0     0.333333          0.7        5  nosignal  \n",
       " 11          1.0     0.333333          0.7        5  nosignal  \n",
       " 12          1.0     0.333333          0.7        5  nosignal  \n",
       " 13          1.0     0.333333          0.7        5  nosignal  \n",
       " 14          1.0     0.333333          0.7        5  nosignal  \n",
       " 15          1.0     0.333333          0.7        5  nosignal  ,\n",
       "                  statistic policy     value     method     T  K noise_func  \\\n",
       " 0                 estimate  (0,1) -0.021817  propscore  5000  3    uniform   \n",
       " 1                   stderr  (0,1)  0.027487  propscore  5000  3    uniform   \n",
       " 2                     bias  (0,1) -0.021817  propscore  5000  3    uniform   \n",
       " 3   90% coverage of t-stat  (0,1)  1.000000  propscore  5000  3    uniform   \n",
       " 4                   t-stat  (0,1) -0.793705  propscore  5000  3    uniform   \n",
       " 5                      mse  (0,1)  0.000476  propscore  5000  3    uniform   \n",
       " 6                 CI_width  (0,1)  0.045213  propscore  5000  3    uniform   \n",
       " 7                    truth  (0,1)  0.000000  propscore  5000  3    uniform   \n",
       " 8                 estimate  (0,2)  0.014244  propscore  5000  3    uniform   \n",
       " 9                   stderr  (0,2)  0.035822  propscore  5000  3    uniform   \n",
       " 10                    bias  (0,2)  0.014244  propscore  5000  3    uniform   \n",
       " 11  90% coverage of t-stat  (0,2)  1.000000  propscore  5000  3    uniform   \n",
       " 12                  t-stat  (0,2)  0.397637  propscore  5000  3    uniform   \n",
       " 13                     mse  (0,2)  0.000203  propscore  5000  3    uniform   \n",
       " 14                CI_width  (0,2)  0.058922  propscore  5000  3    uniform   \n",
       " 15                   truth  (0,2)  0.000000  propscore  5000  3    uniform   \n",
       " \n",
       "     noise_scale  floor_start  floor_decay  initial       dgp  \n",
       " 0           1.0     0.333333          0.7        5  nosignal  \n",
       " 1           1.0     0.333333          0.7        5  nosignal  \n",
       " 2           1.0     0.333333          0.7        5  nosignal  \n",
       " 3           1.0     0.333333          0.7        5  nosignal  \n",
       " 4           1.0     0.333333          0.7        5  nosignal  \n",
       " 5           1.0     0.333333          0.7        5  nosignal  \n",
       " 6           1.0     0.333333          0.7        5  nosignal  \n",
       " 7           1.0     0.333333          0.7        5  nosignal  \n",
       " 8           1.0     0.333333          0.7        5  nosignal  \n",
       " 9           1.0     0.333333          0.7        5  nosignal  \n",
       " 10          1.0     0.333333          0.7        5  nosignal  \n",
       " 11          1.0     0.333333          0.7        5  nosignal  \n",
       " 12          1.0     0.333333          0.7        5  nosignal  \n",
       " 13          1.0     0.333333          0.7        5  nosignal  \n",
       " 14          1.0     0.333333          0.7        5  nosignal  \n",
       " 15          1.0     0.333333          0.7        5  nosignal  ,\n",
       "                  statistic policy     value method     T  K noise_func  \\\n",
       " 0                 estimate  (0,1) -0.023334   lvdl  5000  3    uniform   \n",
       " 1                   stderr  (0,1)  0.028749   lvdl  5000  3    uniform   \n",
       " 2                     bias  (0,1) -0.023334   lvdl  5000  3    uniform   \n",
       " 3   90% coverage of t-stat  (0,1)  1.000000   lvdl  5000  3    uniform   \n",
       " 4                   t-stat  (0,1) -0.811649   lvdl  5000  3    uniform   \n",
       " 5                      mse  (0,1)  0.000544   lvdl  5000  3    uniform   \n",
       " 6                 CI_width  (0,1)  0.047288   lvdl  5000  3    uniform   \n",
       " 7                    truth  (0,1)  0.000000   lvdl  5000  3    uniform   \n",
       " 8                 estimate  (0,2)  0.001494   lvdl  5000  3    uniform   \n",
       " 9                   stderr  (0,2)  0.038493   lvdl  5000  3    uniform   \n",
       " 10                    bias  (0,2)  0.001494   lvdl  5000  3    uniform   \n",
       " 11  90% coverage of t-stat  (0,2)  1.000000   lvdl  5000  3    uniform   \n",
       " 12                  t-stat  (0,2)  0.038811   lvdl  5000  3    uniform   \n",
       " 13                     mse  (0,2)  0.000002   lvdl  5000  3    uniform   \n",
       " 14                CI_width  (0,2)  0.063315   lvdl  5000  3    uniform   \n",
       " 15                   truth  (0,2)  0.000000   lvdl  5000  3    uniform   \n",
       " \n",
       "     noise_scale  floor_start  floor_decay  initial       dgp  \n",
       " 0           1.0     0.333333          0.7        5  nosignal  \n",
       " 1           1.0     0.333333          0.7        5  nosignal  \n",
       " 2           1.0     0.333333          0.7        5  nosignal  \n",
       " 3           1.0     0.333333          0.7        5  nosignal  \n",
       " 4           1.0     0.333333          0.7        5  nosignal  \n",
       " 5           1.0     0.333333          0.7        5  nosignal  \n",
       " 6           1.0     0.333333          0.7        5  nosignal  \n",
       " 7           1.0     0.333333          0.7        5  nosignal  \n",
       " 8           1.0     0.333333          0.7        5  nosignal  \n",
       " 9           1.0     0.333333          0.7        5  nosignal  \n",
       " 10          1.0     0.333333          0.7        5  nosignal  \n",
       " 11          1.0     0.333333          0.7        5  nosignal  \n",
       " 12          1.0     0.333333          0.7        5  nosignal  \n",
       " 13          1.0     0.333333          0.7        5  nosignal  \n",
       " 14          1.0     0.333333          0.7        5  nosignal  \n",
       " 15          1.0     0.333333          0.7        5  nosignal  ,\n",
       "                  statistic policy     value     method     T  K noise_func  \\\n",
       " 0                 estimate  (0,1) -0.027721  two_point  5000  3    uniform   \n",
       " 1                   stderr  (0,1)  0.030714  two_point  5000  3    uniform   \n",
       " 2                     bias  (0,1) -0.027721  two_point  5000  3    uniform   \n",
       " 3   90% coverage of t-stat  (0,1)  1.000000  two_point  5000  3    uniform   \n",
       " 4                   t-stat  (0,1) -0.902552  two_point  5000  3    uniform   \n",
       " 5                      mse  (0,1)  0.000768  two_point  5000  3    uniform   \n",
       " 6                 CI_width  (0,1)  0.050520  two_point  5000  3    uniform   \n",
       " 7                    truth  (0,1)  0.000000  two_point  5000  3    uniform   \n",
       " 8                 estimate  (0,2)  0.008565  two_point  5000  3    uniform   \n",
       " 9                   stderr  (0,2)  0.045600  two_point  5000  3    uniform   \n",
       " 10                    bias  (0,2)  0.008565  two_point  5000  3    uniform   \n",
       " 11  90% coverage of t-stat  (0,2)  1.000000  two_point  5000  3    uniform   \n",
       " 12                  t-stat  (0,2)  0.187821  two_point  5000  3    uniform   \n",
       " 13                     mse  (0,2)  0.000073  two_point  5000  3    uniform   \n",
       " 14                CI_width  (0,2)  0.075006  two_point  5000  3    uniform   \n",
       " 15                   truth  (0,2)  0.000000  two_point  5000  3    uniform   \n",
       " \n",
       "     noise_scale  floor_start  floor_decay  initial       dgp  \n",
       " 0           1.0     0.333333          0.7        5  nosignal  \n",
       " 1           1.0     0.333333          0.7        5  nosignal  \n",
       " 2           1.0     0.333333          0.7        5  nosignal  \n",
       " 3           1.0     0.333333          0.7        5  nosignal  \n",
       " 4           1.0     0.333333          0.7        5  nosignal  \n",
       " 5           1.0     0.333333          0.7        5  nosignal  \n",
       " 6           1.0     0.333333          0.7        5  nosignal  \n",
       " 7           1.0     0.333333          0.7        5  nosignal  \n",
       " 8           1.0     0.333333          0.7        5  nosignal  \n",
       " 9           1.0     0.333333          0.7        5  nosignal  \n",
       " 10          1.0     0.333333          0.7        5  nosignal  \n",
       " 11          1.0     0.333333          0.7        5  nosignal  \n",
       " 12          1.0     0.333333          0.7        5  nosignal  \n",
       " 13          1.0     0.333333          0.7        5  nosignal  \n",
       " 14          1.0     0.333333          0.7        5  nosignal  \n",
       " 15          1.0     0.333333          0.7        5  nosignal  ,\n",
       "                  statistic policy     value          method     T  K  \\\n",
       " 0                 estimate  (0,1) -0.022109  beta_bernoulli  5000  3   \n",
       " 1                   stderr  (0,1)  0.026073  beta_bernoulli  5000  3   \n",
       " 2                     bias  (0,1) -0.022109  beta_bernoulli  5000  3   \n",
       " 3   90% coverage of t-stat  (0,1)  1.000000  beta_bernoulli  5000  3   \n",
       " 4                   t-stat  (0,1) -0.847975  beta_bernoulli  5000  3   \n",
       " 5                      mse  (0,1)  0.000489  beta_bernoulli  5000  3   \n",
       " 6                 CI_width  (0,1)  0.233224  beta_bernoulli  5000  3   \n",
       " 7                    truth  (0,1)  0.000000  beta_bernoulli  5000  3   \n",
       " 8                 estimate  (0,2)  0.013749  beta_bernoulli  5000  3   \n",
       " 9                   stderr  (0,2)  0.034544  beta_bernoulli  5000  3   \n",
       " 10                    bias  (0,2)  0.013749  beta_bernoulli  5000  3   \n",
       " 11  90% coverage of t-stat  (0,2)  1.000000  beta_bernoulli  5000  3   \n",
       " 12                  t-stat  (0,2)  0.398023  beta_bernoulli  5000  3   \n",
       " 13                     mse  (0,2)  0.000189  beta_bernoulli  5000  3   \n",
       " 14                CI_width  (0,2)  0.334108  beta_bernoulli  5000  3   \n",
       " 15                   truth  (0,2)  0.000000  beta_bernoulli  5000  3   \n",
       " \n",
       "    noise_func  noise_scale  floor_start  floor_decay  initial       dgp  \n",
       " 0     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 1     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 2     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 3     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 4     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 5     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 6     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 7     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 8     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 9     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 10    uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 11    uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 12    uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 13    uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 14    uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 15    uniform          1.0     0.333333          0.7        5  nosignal  ,\n",
       "                  statistic policy     value             method     T  K  \\\n",
       " 0                 estimate  (0,1) -0.022109  gamma_exponential  5000  3   \n",
       " 1                   stderr  (0,1)  0.026073  gamma_exponential  5000  3   \n",
       " 2                     bias  (0,1) -0.022109  gamma_exponential  5000  3   \n",
       " 3   90% coverage of t-stat  (0,1)  1.000000  gamma_exponential  5000  3   \n",
       " 4                   t-stat  (0,1) -0.847975  gamma_exponential  5000  3   \n",
       " 5                      mse  (0,1)  0.000489  gamma_exponential  5000  3   \n",
       " 6                 CI_width  (0,1)  0.146519  gamma_exponential  5000  3   \n",
       " 7                    truth  (0,1)  0.000000  gamma_exponential  5000  3   \n",
       " 8                 estimate  (0,2)  0.013749  gamma_exponential  5000  3   \n",
       " 9                   stderr  (0,2)  0.034544  gamma_exponential  5000  3   \n",
       " 10                    bias  (0,2)  0.013749  gamma_exponential  5000  3   \n",
       " 11  90% coverage of t-stat  (0,2)  1.000000  gamma_exponential  5000  3   \n",
       " 12                  t-stat  (0,2)  0.398023  gamma_exponential  5000  3   \n",
       " 13                     mse  (0,2)  0.000189  gamma_exponential  5000  3   \n",
       " 14                CI_width  (0,2)  0.215642  gamma_exponential  5000  3   \n",
       " 15                   truth  (0,2)  0.000000  gamma_exponential  5000  3   \n",
       " \n",
       "    noise_func  noise_scale  floor_start  floor_decay  initial       dgp  \n",
       " 0     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 1     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 2     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 3     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 4     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 5     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 6     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 7     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 8     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 9     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 10    uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 11    uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 12    uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 13    uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 14    uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 15    uniform          1.0     0.333333          0.7        5  nosignal  ,\n",
       "                  statistic policy     value             method     T  K  \\\n",
       " 0                 estimate  (0,1) -0.022109  sample_mean_naive  5000  3   \n",
       " 1                   stderr  (0,1)  0.026073  sample_mean_naive  5000  3   \n",
       " 2                     bias  (0,1) -0.022109  sample_mean_naive  5000  3   \n",
       " 3   90% coverage of t-stat  (0,1)  1.000000  sample_mean_naive  5000  3   \n",
       " 4                   t-stat  (0,1) -0.847975  sample_mean_naive  5000  3   \n",
       " 5                      mse  (0,1)  0.000489  sample_mean_naive  5000  3   \n",
       " 6                 CI_width  (0,1)  0.042886  sample_mean_naive  5000  3   \n",
       " 7                    truth  (0,1)  0.000000  sample_mean_naive  5000  3   \n",
       " 8                 estimate  (0,2)  0.013749  sample_mean_naive  5000  3   \n",
       " 9                   stderr  (0,2)  0.034544  sample_mean_naive  5000  3   \n",
       " 10                    bias  (0,2)  0.013749  sample_mean_naive  5000  3   \n",
       " 11  90% coverage of t-stat  (0,2)  1.000000  sample_mean_naive  5000  3   \n",
       " 12                  t-stat  (0,2)  0.398023  sample_mean_naive  5000  3   \n",
       " 13                     mse  (0,2)  0.000189  sample_mean_naive  5000  3   \n",
       " 14                CI_width  (0,2)  0.056820  sample_mean_naive  5000  3   \n",
       " 15                   truth  (0,2)  0.000000  sample_mean_naive  5000  3   \n",
       " \n",
       "    noise_func  noise_scale  floor_start  floor_decay  initial       dgp  \n",
       " 0     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 1     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 2     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 3     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 4     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 5     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 6     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 7     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 8     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 9     uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 10    uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 11    uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 12    uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 13    uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 14    uniform          1.0     0.333333          0.7        5  nosignal  \n",
       " 15    uniform          1.0     0.333333          0.7        5  nosignal  ]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabs_contrasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the `scores` and `probs` generated from the experiment. We will use them with banditsCI R package to compare the estimates and standard errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"./results/scores.csv\", scores, delimiter=\",\")\n",
    "np.savetxt(\"./results/probs.csv\", probs, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if on_sherlock():\n",
    "    write_dir = get_sherlock_dir('adaptive-confidence-intervals', 'simulations', create=True)\n",
    "    print(f\"saving at {write_dir}\")\n",
    "else:\n",
    "     write_dir = join(os.getcwd(), 'results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = pd.concat(df_stats, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving information about contrasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_contrast = compose_filename(f'contrast', 'pkl')\n",
    "write_path_contrast = os.path.join(write_dir, filename_contrast)\n",
    "\n",
    "df_contrast = df_stats.query(\n",
    "    '(policy == \"(0,1)\" or policy == \"(0,2)\") and '\n",
    "    'statistic in [\"estimate\", \"stderr\", \"mse\", \"bias\", \"CI_width\"] and '\n",
    "    \"method in ['uniform', 'two_point', 'sample_mean_naive']\")\n",
    "df_contrast.to_pickle(write_path_contrast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    statistic policy     value             method     T  K noise_func  \\\n",
      "264  estimate  (0,1) -0.027020            uniform  5000  3    uniform   \n",
      "265    stderr  (0,1)  0.031184            uniform  5000  3    uniform   \n",
      "266      bias  (0,1) -0.027020            uniform  5000  3    uniform   \n",
      "269       mse  (0,1)  0.000730            uniform  5000  3    uniform   \n",
      "270  CI_width  (0,1)  0.051294            uniform  5000  3    uniform   \n",
      "272  estimate  (0,2) -0.013112            uniform  5000  3    uniform   \n",
      "273    stderr  (0,2)  0.044075            uniform  5000  3    uniform   \n",
      "274      bias  (0,2) -0.013112            uniform  5000  3    uniform   \n",
      "277       mse  (0,2)  0.000172            uniform  5000  3    uniform   \n",
      "278  CI_width  (0,2)  0.072497            uniform  5000  3    uniform   \n",
      "312  estimate  (0,1) -0.027721          two_point  5000  3    uniform   \n",
      "313    stderr  (0,1)  0.030714          two_point  5000  3    uniform   \n",
      "314      bias  (0,1) -0.027721          two_point  5000  3    uniform   \n",
      "317       mse  (0,1)  0.000768          two_point  5000  3    uniform   \n",
      "318  CI_width  (0,1)  0.050520          two_point  5000  3    uniform   \n",
      "320  estimate  (0,2)  0.008565          two_point  5000  3    uniform   \n",
      "321    stderr  (0,2)  0.045600          two_point  5000  3    uniform   \n",
      "322      bias  (0,2)  0.008565          two_point  5000  3    uniform   \n",
      "325       mse  (0,2)  0.000073          two_point  5000  3    uniform   \n",
      "326  CI_width  (0,2)  0.075006          two_point  5000  3    uniform   \n",
      "360  estimate  (0,1) -0.022109  sample_mean_naive  5000  3    uniform   \n",
      "361    stderr  (0,1)  0.026073  sample_mean_naive  5000  3    uniform   \n",
      "362      bias  (0,1) -0.022109  sample_mean_naive  5000  3    uniform   \n",
      "365       mse  (0,1)  0.000489  sample_mean_naive  5000  3    uniform   \n",
      "366  CI_width  (0,1)  0.042886  sample_mean_naive  5000  3    uniform   \n",
      "368  estimate  (0,2)  0.013749  sample_mean_naive  5000  3    uniform   \n",
      "369    stderr  (0,2)  0.034544  sample_mean_naive  5000  3    uniform   \n",
      "370      bias  (0,2)  0.013749  sample_mean_naive  5000  3    uniform   \n",
      "373       mse  (0,2)  0.000189  sample_mean_naive  5000  3    uniform   \n",
      "374  CI_width  (0,2)  0.056820  sample_mean_naive  5000  3    uniform   \n",
      "\n",
      "     noise_scale  floor_start  floor_decay  initial       dgp  \n",
      "264          1.0     0.333333          0.7        5  nosignal  \n",
      "265          1.0     0.333333          0.7        5  nosignal  \n",
      "266          1.0     0.333333          0.7        5  nosignal  \n",
      "269          1.0     0.333333          0.7        5  nosignal  \n",
      "270          1.0     0.333333          0.7        5  nosignal  \n",
      "272          1.0     0.333333          0.7        5  nosignal  \n",
      "273          1.0     0.333333          0.7        5  nosignal  \n",
      "274          1.0     0.333333          0.7        5  nosignal  \n",
      "277          1.0     0.333333          0.7        5  nosignal  \n",
      "278          1.0     0.333333          0.7        5  nosignal  \n",
      "312          1.0     0.333333          0.7        5  nosignal  \n",
      "313          1.0     0.333333          0.7        5  nosignal  \n",
      "314          1.0     0.333333          0.7        5  nosignal  \n",
      "317          1.0     0.333333          0.7        5  nosignal  \n",
      "318          1.0     0.333333          0.7        5  nosignal  \n",
      "320          1.0     0.333333          0.7        5  nosignal  \n",
      "321          1.0     0.333333          0.7        5  nosignal  \n",
      "322          1.0     0.333333          0.7        5  nosignal  \n",
      "325          1.0     0.333333          0.7        5  nosignal  \n",
      "326          1.0     0.333333          0.7        5  nosignal  \n",
      "360          1.0     0.333333          0.7        5  nosignal  \n",
      "361          1.0     0.333333          0.7        5  nosignal  \n",
      "362          1.0     0.333333          0.7        5  nosignal  \n",
      "365          1.0     0.333333          0.7        5  nosignal  \n",
      "366          1.0     0.333333          0.7        5  nosignal  \n",
      "368          1.0     0.333333          0.7        5  nosignal  \n",
      "369          1.0     0.333333          0.7        5  nosignal  \n",
      "370          1.0     0.333333          0.7        5  nosignal  \n",
      "373          1.0     0.333333          0.7        5  nosignal  \n",
      "374          1.0     0.333333          0.7        5  nosignal  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Reading the pickle file into a DataFrame\n",
    "df_contrast = pd.read_pickle(write_path_contrast)\n",
    "\n",
    "# Printing the DataFrame\n",
    "print(df_contrast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the estimate and std.error from uniform and two_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistic     method policy  estimate  std.error\n",
      "0          two_point  (0,1) -0.027721   0.030714\n",
      "1          two_point  (0,2)  0.008565   0.045600\n",
      "2            uniform  (0,1) -0.027020   0.031184\n",
      "3            uniform  (0,2) -0.013112   0.044075\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Filter the rows where the statistic is either 'estimate' or 'stderr' and method is 'uniform' or 'two_point'\n",
    "filtered_df = df_contrast.query(\"statistic in ['estimate', 'stderr'] and method in ['uniform', 'two_point']\")\n",
    "\n",
    "# Pivot the table to get 'estimate' and 'stderr' as columns\n",
    "pivot_df = filtered_df.pivot_table(index=['method', 'policy'], columns='statistic', values='value', aggfunc='first').reset_index()\n",
    "\n",
    "# Rename the columns appropriately\n",
    "comparison_df = pivot_df.rename(columns={'estimate': 'estimate', 'stderr': 'std.error'})\n",
    "\n",
    "# Filter to only include the rows for 'uniform' and 'two_point' methods\n",
    "comparison_df = comparison_df[comparison_df['method'].isin(['uniform', 'two_point'])]\n",
    "\n",
    "# Display the DataFrame\n",
    "print(comparison_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adaptive_CI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
